# Backpropagation and the brain
DeepMind 的新论文。延续之前他们的研究方向，继续探究人脑的机制。
这篇论文看起来主要是在之前的神经学研究基础之上做了一些总结和展开。

**论文地址**：https://sci-hub.tw/10.1038/s41583-020-0277-3
**Reddit讨论串**：https://www.reddit.com/r/MachineLearning/comments/g3gvfm/r_backpropagation_and_the_brain/

简单总结
=======

Backprop in the brain?
-----
这里大量引用了神经科学领域的论文。
虽然目前并没有直接的研究证据，但是 BP 居然真的是行为上和人脑最为吻合的。
论文中举出了在视觉和听觉皮层的例子，也举出了感知学习时感受野的变化。在上述领域中，BP 算法都能解释人脑的行为。
甚至在视觉皮层中，真的有神经元会去比较预测画面和实际画面的差异。
另外，目前的 DL 领域中，未使用 BP 算法的模型，性能上与传统模型也有着巨大的差距。
因此，大脑非常有可能利用某种回传 error 的方式进行学习，尽管并不是BP。

Problems with backprop
-------
**对称问题**
BP的算法这里不赘述。但它的进行必须有 error signal 的反向传递，且正向反向的网络应当是**对称**（权重一致）的。
已证明的确可以沿原突触反向传递，但其速度过慢，不足以支撑 BP 算法。
但最新进展发现，可以不必要求对称。参考文中文献，关键词为 Random Feedback Alignment。这里在BP的时候，没有使用正向的权重矩阵，而是使用了一个随机（但有约束）的矩阵。
上述算法经过一定优化后，有能力训练非常深的网络。太扯了吧！

**Error Signal 有符号**
有符号的信号在反向传播时，对于皮层来说存在困难。因为由于激活函数的存在，传递将会被阻断。